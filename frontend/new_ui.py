import os
import sys
import threading
from typing import Optional
import asyncio
from queue import Queue, Empty
import time
import warnings

import gradio as gr
import pynini
import onnxruntime as ort
from punctuators.models import PunctCapSegModelONNX

from api.services.chunkformer_stt import ChunkFormer
from api.private_config import *
from api.config import *          # ƒë·ªÉ l·∫•y SUMMARIZE_DOCUMENT_PROMPT, v.v.
from api.services.vcdb_faiss import VectorStore
from api.services.local_llm import LanguageModelOllama  # b·∫£n ƒë√£ c√≥ async_generate

warnings.filterwarnings("ignore")

# =========================
# ITN MODEL
# =========================

def init_itn_model(itn_model_dir: str):
    print(f"Loading ITN model from: {itn_model_dir}")
    far_dir = os.path.join(itn_model_dir, "far")
    classifier_far = os.path.join(far_dir, "classify/tokenize_and_classify.far")
    verbalizer_far = os.path.join(far_dir, "verbalize/verbalize.far")

    if not (os.path.exists(classifier_far) and os.path.exists(verbalizer_far)):
        print(f"ERROR: Missing .far files in {far_dir}", file=sys.stderr)
        sys.exit(1)

    try:
        reader_classifier = pynini.Far(classifier_far)
        reader_verbalizer = pynini.Far(verbalizer_far)
        classifier = reader_classifier.get_fst()
        verbalizer = reader_verbalizer.get_fst()
        print("ITN model ready.")
        return classifier, verbalizer
    except Exception as e:
        print(f"Error loading ITN model: {e}", file=sys.stderr)
        sys.exit(1)


# =========================
# INIT GLOBAL MODELS
# =========================

chunkformer = ChunkFormer(model_checkpoint=CHUNKFORMER_CHECKPOINT)
punc_model = PunctCapSegModelONNX.from_pretrained(
    "1-800-BAD-CODE/xlm-roberta_punctuation_fullstop_truecase",
    ort_providers=["CPUExecutionProvider"],
)
itn_classifier, itn_verbalizer = init_itn_model(ITN_REPO)

# ---- RAG / LLM t·ª´ lu·ªìng c≈© ----
llm = LanguageModelOllama("shmily_006/Qw3:4b_4bit", temperature=0.5)
faiss = VectorStore("luat_hon_nhan_gia_dinh")

# =========================
# RAG QUEUES & GLOBALS (lu·ªìng c≈©)
# =========================
job_queue = Queue(maxsize=0)
summarizer_queue = Queue(maxsize=0)

# =========================
# ASYNC EVENT LOOP THREAD (lu·ªìng c≈©)
# =========================
_ASYNC_LOOP: asyncio.AbstractEventLoop | None = None
_ASYNC_THREAD: threading.Thread | None = None

def _loop_worker(loop: asyncio.AbstractEventLoop):
    asyncio.set_event_loop(loop)
    loop.run_forever()

def start_async_loop():
    global _ASYNC_LOOP, _ASYNC_THREAD
    if _ASYNC_LOOP is None:
        _ASYNC_LOOP = asyncio.new_event_loop()
        _ASYNC_THREAD = threading.Thread(target=_loop_worker, args=(_ASYNC_LOOP,), daemon=True)
        _ASYNC_THREAD.start()

def stop_async_loop():
    global _ASYNC_LOOP
    if _ASYNC_LOOP and _ASYNC_LOOP.is_running():
        _ASYNC_LOOP.call_soon_threadsafe(_ASYNC_LOOP.stop)

def run_async(coro, timeout: float | None = None):
    """
    Submit coroutine to the background loop from any thread and wait for result.
    """
    fut = asyncio.run_coroutine_threadsafe(coro, _ASYNC_LOOP)
    return fut.result(timeout=timeout)

# Kh·ªüi ƒë·ªông event loop n·ªÅn NGAY t·ª´ ƒë·∫ßu
start_async_loop()

# =========================
# T√ìM T·∫ÆT: prompt builder (lu·ªìng c≈©)
# =========================
def build_summary_prompt(utterance: str, docs) -> str:
    return SUMMARIZE_DOCUMENT_PROMPT.format(utterance=utterance, related_docs=docs)

# =========================
# GLOBAL STATE CHO UI M·ªöI
# =========================
asr_thread: Optional[threading.Thread] = None
stop_event = threading.Event()
transcript_lock = threading.Lock()

# formatted transcript (Punc + ITN)
transcript_text = ""   # c·ªôt tr√°i: script cu·ªôc h·ªçp
commit_log = ""        # log new_commit (backend d√πng n·∫øu c·∫ßn)

# summary t·ª´ RAG (c·ªôt ph·∫£i)
summary_lock = threading.Lock()
summary_text = ""      # c·ªôt ph·∫£i: summarize docs / t√≥m t·∫Øt

# buffer ƒë·ªÉ gom new_commit tr∆∞·ªõc khi ƒë·∫©y sang RAG
rag_buffer = []
rag_buffer_lock = threading.Lock()

# =========================
# WORKER CH√çNH CHO RAG (lu·ªìng c≈©)
# =========================
def worker_loop(worker_id: int):
    print(f"[Worker-{worker_id}] Starting")
    while True:
        try:
            text = job_queue.get(timeout=1.0)
        except Empty:
            continue

        try:
            # 1) Chu·∫©n ho√° b·∫±ng async_generate (non-stream) ch·∫°y tr√™n loop n·ªÅn
            normalize_prompt = llm.normalize_text(text)
            normalized = run_async(llm.async_generate(normalize_prompt), timeout=60.0)
            print(f"[Worker-{worker_id}] C√¢u ƒë√£ ƒë∆∞·ª£c chu·∫©n h√≥a v√† t·ªëi ∆∞u:", text, "\n", normalized)
            print("___________________________________________________________________________________________________________")

            if not normalized or normalized.strip().casefold() == "none":
                continue
            else:
                # 2) Retrieve t√†i li·ªáu li√™n quan
                related_docs = faiss.hybrid_search(normalized)

                # 3) ƒê·∫©y sang summarizer_queue ƒë·ªÉ t√≥m t·∫Øt song song
                summarizer_queue.put({
                    "utterance": normalized,
                    "related_docs": related_docs,
                    "ts": time.time()
                })

        except Exception as e:
            print(f"[Worker-{worker_id}] ERROR processing job: {e}")
        finally:
            job_queue.task_done()

def start_workers(num_workers: int = 2):
    for i in range(num_workers):
        t = threading.Thread(target=worker_loop, args=(i+1,), daemon=True)
        t.start()

# =========================
# SUMMARIZER LOOP (song song, lu·ªìng c≈©)
# =========================
def summarizer_loop():
    global summary_text
    print("[Summarizer] Starting")
    while True:
        try:
            item = summarizer_queue.get(timeout=1.0)
        except Empty:
            continue

        try:
            utter = item.get("utterance", "")
            docs = item.get("related_docs", [])

            # Build prompt v√† g·ªçi async_generate tr√™n loop n·ªÅn
            sum_prompt = build_summary_prompt(utter, docs)
            summary = run_async(llm.async_generate(sum_prompt), timeout=60.0)

            # C·∫≠p nh·∫≠t v√πng summary cho UI (c·ªôt ph·∫£i)
            with summary_lock:
                if summary_text:
                    summary_text = (
                        summary_text
                        + "\n\n‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ  NEW SUMMARY  ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n"
                        + summary.strip()
                    )
                else:
                    summary_text = summary.strip()

            # (t√πy ch·ªçn) log ra console
            print("\n================= [SUMMARY] =================")
            print(summary.strip())
            print("=============================================\n")

        except Exception as e:
            print(f"[Summarizer] ERROR: {e}")
        finally:
            try:
                summarizer_queue.task_done()
            except Exception:
                pass

def start_summarizer():
    t = threading.Thread(target=summarizer_loop, daemon=True)
    t.start()

# Kh·ªüi ƒë·ªông workers & summarizer
start_workers(num_workers=2)
start_summarizer()


# =========================
# CALLBACK FROM CHUNKFORMER (lu·ªìng m·ªõi + RAG)
# =========================
def enqueue_rag_with_overlap(new_commit: str):
    """
    Gom 2 new_commit from asr l·∫°i v·ªõi nhau (c·ª≠a s·ªï tr∆∞·ª£t size=2, overlap=1),
    sau ƒë√≥ m·ªõi ƒë·∫©y v√†o job_queue.

    V√≠ d·ª•:
      commits: A, B, C, D
      g·ª≠i v√†o RAG: (A+B), (B+C), (C+D)
    """
    global rag_buffer

    new_commit = (new_commit or "").strip()
    if not new_commit:
        return

    with rag_buffer_lock:
        # Th√™m commit m·ªõi v√†o buffer
        rag_buffer.append(new_commit)

        # Ch∆∞a ƒë·ªß 2 c√¢u th√¨ ch∆∞a g·ª≠i v√†o RAG
        if len(rag_buffer) < 2:
            return

        # ƒê·ªß 2 c√¢u: gom l·∫°i th√†nh 1 ƒëo·∫°n
        combined = rag_buffer[0] + " " + rag_buffer[1]

        try:
            job_queue.put_nowait(combined)
        except Exception as e:
            print(f"[enqueue_rag_with_overlap] Cannot enqueue combined text: {e}")

        # Gi·ªØ overlap = 1: gi·ªØ l·∫°i c√¢u cu·ªëi c√πng ƒë·ªÉ gh√©p v·ªõi commit ti·∫øp theo
        rag_buffer = [rag_buffer[-1]]


def on_update(event: str, payload: dict):
    """
    Callback t·ª´ chunkformer_asr_realtime_punc_norm:

      - event = "partial":
            payload: {"display", "committed", "active"}
      - event = "commit":
            payload: {"new_commit", "committed", "display"}
      - event = "final_flush":
            payload: {"text"}
    """
    global transcript_text, commit_log

    with transcript_lock:
        if event == "partial":
            display = (payload.get("display") or "").strip()
            if display:
                transcript_text = display

        elif event == "commit":
            # update transcript (∆∞u ti√™n display n·∫øu c√≥, fallback committed)
            display = (payload.get("display")
                       or payload.get("committed")
                       or "").strip()
            if display:
                transcript_text = display
            # L·∫•y new_commit ƒë·ªÉ log (backend) + gom v√†o chunk 2-c√¢u tr∆∞·ªõc khi ƒë·∫©y sang RAG
            new_commit = (payload.get("new_commit") or "").strip()
            if new_commit:
                if commit_log:
                    commit_log_val = f"{commit_log}\n{new_commit}"
                else:
                    commit_log_val = new_commit
                commit_log = commit_log_val

                enqueue_rag_with_overlap(new_commit)

        elif event == "final_flush":
            text = (payload.get("text") or "").strip()
            if text:
                transcript_text = text
                # try:
                #     job_queue.put_nowait(text)
                # except Exception as e:
                #     print(f"[on_update] Cannot enqueue final text to job_queue: {e}")


# =========================
# ASR WORKER (lu·ªìng m·ªõi)
# =========================
def asr_worker():
    """
    Ch·∫°y tr√™n server, ƒë·ªçc mic local qua chunkformer_asr_realtime_punc_norm
    (ƒë√£ t√≠ch h·ª£p VAD + Punc + ITN).
    D·ª´ng khi stop_event ƒë∆∞·ª£c set.
    """
    try:
        chunkformer.chunkformer_asr_realtime_punc_norm(
            mic_sr=16000,
            stream_chunk_sec=0.5,
            lookahead_sec=0.5,
            left_context_size=128,
            right_context_size=32,
            max_overlap_match=32,
            # VAD
            vad_threshold=0.01,
            vad_min_silence_blocks=2,
            # Punc + ITN
            punc_model=punc_model,
            punc_window_words=100,
            punc_commit_margin_words=50,
            itn_classifier=itn_classifier,
            itn_verbalizer=itn_verbalizer,
            # Control
            on_update=on_update,
            stop_event=stop_event,
            return_final=False,
        )
    except Exception as e:
        print("[ASR] Error:", e, file=sys.stderr)


# =========================
# GRADIO CALLBACKS
# =========================
def start_asr():
    """
    Start button:
      - reset transcript + summary
      - clear stop_event
      - spawn asr_worker thread n·∫øu ch∆∞a ch·∫°y
    """
    global asr_thread, transcript_text, commit_log, summary_text
    with transcript_lock:
        transcript_text = ""
        commit_log = ""
    with summary_lock:
        summary_text = ""

    stop_event.clear()

    if asr_thread is None or not asr_thread.is_alive():
        t = threading.Thread(target=asr_worker, daemon=True)
        t.start()
        asr_thread = t
        return (
            gr.update(value=""),  # transcript_box
            gr.update(value=""),  # summary_box
            "ƒêang l·∫Øng nghe üéß",   # status
        )
    else:
        return (
            gr.update(),          # transcript_box
            gr.update(),          # summary_box
            "ASR ƒë√£ ch·∫°y r·ªìi ‚úÖ",
        )


def stop_asr():
    """
    Stop button: set stop_event, worker s·∫Ω t·ª± tho√°t v√≤ng while.
    """
    stop_event.set()
    return "ƒê√£ g·ª≠i t√≠n hi·ªáu d·ª´ng ‚èπÔ∏è"


def poll_ui():
    """
    ƒê∆∞·ª£c g·ªçi b·ªüi gr.Timer ƒë·ªÉ c·∫≠p nh·∫≠t UI ƒë·ªãnh k·ª≥.
    """
    with transcript_lock:
        txt = transcript_text
    with summary_lock:
        sumtxt = summary_text
    return gr.update(value=txt), gr.update(value=sumtxt)


# =========================
# CHATBOT HANDLER (c·ªôt gi·ªØa)
# =========================
def chat_qa(history, message):
    """
    Handler t·∫°m th·ªùi cho chatbot.
    Backend RAG h·ªèi ƒë√°p s·∫Ω thay th·∫ø logic n√†y sau.
    """
    if not message:
        return history, ""
    response = (
        "Ch·ª©c nƒÉng h·ªèi ƒë√°p Chatbot v·ªÅ cu·ªôc h·ªçp ch∆∞a ho√†n thi·ªán.\n"
        f"B·∫°n v·ª´a h·ªèi: {message}"
    )
    history = history + [(message, response)]
    return history, ""


# =========================
# BUILD UI (3 c·ªôt, t·ªëi gi·∫£n & full-height)
# =========================

with gr.Blocks() as demo:
    gr.Markdown("### üìù Realtime Meeting Assistant")

    # H√†ng n√∫t ƒëi·ªÅu khi·ªÉn
    with gr.Row():
        with gr.Column(scale=1):
            start_btn = gr.Button("‚ñ∂Ô∏è B·∫Øt ƒë·∫ßu ghi √¢m", variant="primary")
        with gr.Column(scale=1):
            stop_btn = gr.Button("‚èπÔ∏è D·ª´ng", variant="secondary")
        with gr.Column(scale=1):
            status = gr.Markdown("ƒêang idle‚Ä¶")

    # Ba c·ªôt ch√≠nh
    with gr.Row(elem_classes=["main-row"]):
        # C·ªôt tr√°i: Transcript
        with gr.Column(scale=2, elem_classes=["main-col"]):
            gr.Markdown("**Transcript cu·ªôc h·ªçp**")
            transcript_box = gr.Textbox(
                show_label=False,
                placeholder="Transcript",
                lines=37,
                interactive=False,
                elem_classes=["full-height-box"],
            )

        # C·ªôt gi·ªØa: Chatbot
        with gr.Column(scale=3, elem_classes=["main-col"]):
            gr.Markdown("**Chatbot h·ªèi ƒë√°p v·ªÅ cu·ªôc h·ªçp**")
            chatbot = gr.Chatbot(
                label="",
                elem_classes=["full-height-chatbot"], resizable=True, height=680
            )
            # √î nh·∫≠p + n√∫t g·ª≠i nh·ªè n·∫±m trong Textbox (submit_btn)
            chat_input = gr.Textbox(
                show_label=False,
                placeholder="ƒê·∫∑t c√¢u h·ªèi v·ªÅ n·ªôi dung cu·ªôc h·ªçp...",
                lines=2,
                submit_btn=True,   # n√∫t g·ª≠i nh·ªè ·ªü trong textbox
            )

        # C·ªôt ph·∫£i: Summaries / Docs
        with gr.Column(scale=2, elem_classes=["main-col"]):
            gr.Markdown("**T√≥m t·∫Øt & t√†i li·ªáu li√™n quan**")
            summary_box = gr.Textbox(
                show_label=False,
                placeholder="C√°c ƒëo·∫°n t√≥m t·∫Øt t·ª´ RAG s·∫Ω hi·ªÉn th·ªã t·∫°i ƒë√¢y...",
                lines=37,
                interactive=False,
                elem_classes=["full-height-box"],
            )

    # Start: reset + ch·∫°y thread ASR
    start_btn.click(
        fn=start_asr,
        outputs=[transcript_box, summary_box, status],
    )

    # Stop: set stop_event
    stop_btn.click(
        fn=stop_asr,
        outputs=[status],
    )

    # Timer: c·∫≠p nh·∫≠t transcript & summary
    timer = gr.Timer(value=0.25, active=True)
    timer.tick(
        fn=poll_ui,
        outputs=[transcript_box, summary_box],
    )

    # Chatbot wiring: ch·ªâ d√πng submit c·ªßa Textbox
    chat_input.submit(
        fn=chat_qa,
        inputs=[chatbot, chat_input],
        outputs=[chatbot, chat_input],
    )

if __name__ == "__main__":
    demo.launch(server_name="0.0.0.0", server_port=7860)
    # stop_async_loop()
