import sounddevice as sd
import numpy as np
import queue
import threading
from faster_whisper import WhisperModel
import soundfile as sf
import pyloudnorm as pyln
import soundfile as sf
import pyloudnorm as pyln
import os
import tempfile
# Settings
samplerate = 16000
block_duration = 4  # seconds
chunk_duration = 8  # seconds
channels = 1
frames_per_block = int(samplerate * block_duration)
frames_per_chunk = int(samplerate * chunk_duration)

audio_queue = queue.Queue()
audio_buffer = []

temp_dir = tempfile.mkdtemp(prefix="audio_chunks_")  # T·∫°o th∆∞ m·ª•c t·∫°m
os.makedirs(temp_dir, exist_ok=True)


"""
  H∆∞·ªõng d·∫´n s·ª≠ d·ª•ng t·∫•t c·∫£ compute_type trong Faster-Whisper.

  Args:
      model_size (str): K√≠ch th∆∞·ªõc model (e.g., "tiny", "base", "small", "medium", "large-v3").
      compute_type (str): Lo·∫°i t√≠nh to√°n (xem m√¥ t·∫£ b√™n d∆∞·ªõi).
      device (str): "cuda" cho GPU ho·∫∑c "cpu" cho CPU.

  Compute_type h·ªó tr·ª£:
  1. "float32"  - ƒê·ªô ch√≠nh x√°c cao nh·∫•t, ch·∫≠m, t·ªën b·ªô nh·ªõ. D√πng ƒë·ªÉ debug.
  2. "float16"  - C√¢n b·∫±ng t·ªët gi·ªØa t·ªëc ƒë·ªô v√† ƒë·ªô ch√≠nh x√°c (m·∫∑c ƒë·ªãnh n√™n d√πng tr√™n GPU).
  3. "int8"     - T·ªëc ƒë·ªô nhanh nh·∫•t, ti·∫øt ki·ªám VRAM, ƒë·ªô ch√≠nh x√°c gi·∫£m nh·∫π.
  4. "int8_float16" - K·∫øt h·ª£p int8 v√† float16 (√≠t d√πng, th·ª≠ nghi·ªám).
  5. "int8_float32" - D√πng int8 nh∆∞ng ki·ªÉm tra b·∫±ng float32 (ƒë·ªô ch√≠nh x√°c cao h∆°n int8 thu·∫ßn).
  6. "bf16"     - H·ªó tr·ª£ GPU Ampere (RTX 30xx+), ti·∫øt ki·ªám b·ªô nh·ªõ nh∆∞ float16.
  """
# Model setup: medium.en + float16 (optimized for 3x80)
model = WhisperModel("large-v3", device="cuda", compute_type="float16")  # use model size "medium.en" for faster

def audio_callback(indata, frames, time, status):
    if status:
        print(status)
    audio_queue.put(indata.copy())

def recorder():
    with sd.InputStream(samplerate=samplerate, channels=channels,
                      callback=audio_callback, blocksize=frames_per_block):
        print("üîç Listening... Press Ctrl+C to stop.")
        while True:
            sd.sleep(100)

def check_loud_ness(audio_data,chunk_number):
    # L∆∞u file WAV
    chunk_path = os.path.join(temp_dir, f"chunk_{chunk_number}.wav")
    sf.write(chunk_path, audio_data, samplerate)

    data, rate = sf.read(chunk_path)
    meter = pyln.Meter(rate)
    loudness = meter.integrated_loudness(data)
    if loudness > -50:
        # print("speaking..."+str(loudness)+ "chunk number: "+str(chunk_number))
        return True
    return False

def transcriber():
    global audio_buffer
    chunk_counter = 0

    while True:
        block = audio_queue.get()
        if check_loud_ness(block, chunk_counter) == True:
            # print('okay hear you '+ str(chunk_counter))
            audio_buffer.append(block)

            total_frames = sum(len(b) for b in audio_buffer)

            if total_frames >= frames_per_chunk:
                audio_data = np.concatenate(audio_buffer)[:frames_per_chunk]
                audio_buffer = []  # Clear buffer
                audio_data = audio_data.flatten().astype(np.float32)


                # X·ª≠ l√Ω v·ªõi Whisper
                segments, _ = model.transcribe(
                    audio_data,
                    language="vi",
                    beam_size=5
                )

                for segment in segments:
                    print(f"{segment.text}")

                chunk_counter += 1


# Start threads
threading.Thread(target=recorder, daemon=True).start()
transcriber()